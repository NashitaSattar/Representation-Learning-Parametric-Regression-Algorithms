# Representation Learning and Parametric Regression-Algorithms
This Jupyter Notebook demonstrates a complete machine learning pipeline for classification and regression tasks using multiple structured datasets. It includes data loading, preprocessing, exploratory data analysis, algorithmic modeling, and dimensionality reduction techniques for insightful visualizations. The algorithms used for regression are k-nearest neighbours, random forests, and gradient tree boosting, where root mean squared error (RMSE) is used to measure performance. T-SNE, PCA, and LDA are used on the datasets to demonstrate feature extraction to create new representations of the data.
